<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EndoPerfect: A Hybrid NeRF-Stereo Vision Approach</title>
    <style>
        /* Previous styles remain the same */
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            color: #333;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 2rem;
        }

        .header {
            text-align: center;
            padding: 3rem 0;
        }

        .title {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            line-height: 1.3;
        }

        .authors {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 2rem;
            max-width: 1000px;
            margin: 2rem auto;
            text-align: center;
        }

        .author {
            margin-bottom: 1rem;
        }

        .author-name {
            font-weight: bold;
            margin-bottom: 0.5rem;
        }

        .affiliation {
            font-size: 0.9rem;
            margin-bottom: 0.5rem;
        }

        .department {
            font-size: 0.9rem;
            color: #666;
            margin-bottom: 0.5rem;
        }

        .email {
            font-size: 0.8rem;
            color: #0366d6;
        }

        /* New styles for buttons with icons */
        .links {
            margin: 2rem 0;
            text-align: center;
        }

        .resource-button {
            display: inline-flex;
            align-items: center;
            background-color: #24292e;
            color: white;
            padding: 8px 16px;
            margin: 0 8px;
            border-radius: 6px;
            text-decoration: none;
            font-weight: 500;
            transition: background-color 0.2s;
        }

        .resource-button:hover {
            background-color: #2c3136;
        }

        .resource-button img {
            width: 20px;
            height: 20px;
            margin-right: 8px;
        }

        .main-image {
            max-width: 100%;
            height: auto;
            margin: 2rem auto;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }

        .abstract {
            background-color: #f6f8fa;
            padding: 2rem;
            border-radius: 8px;
            margin: 2rem 0;
        }

        .abstract h2 {
            margin-top: 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Previous header and authors content remains the same -->
        <div class="header">
            <!-- ... previous title and authors ... -->
        </div>

        <div class="links">
            <a href="https://arxiv.org/abs/2410.04041" class="resource-button">
                <img src="/api/placeholder/20/20" alt="pdf" /> Paper
            </a>
            <a href="https://github.com/PearsonChen123/EndoPerfect" class="resource-button">
                <img src="/api/placeholder/20/20" alt="code" /> Code
            </a>
            <a href="#" class="resource-button">
                <img src="/api/placeholder/20/20" alt="dataset" /> Dataset
            </a>
        </div>

        <img src="/api/placeholder/800/400" alt="pipeline" class="main-image" />

        <div class="abstract">
            <h2>Abstract</h2>
            <p>
                <!-- Add your abstract text here -->
                3D reconstruction in endoscopic sinus surgery (ESS) demands exceptional accuracy, with the mean error and standard deviation necessitating within the range of a single CT slice (0.625 mm), as the critical structures in the nasal cavity are situated within submillimeter distances from surgical instruments. This poses a formidable challenge when using conventional monocular endoscopes. Depth estimation is crucial for 3D reconstruction, yet existing depth estimation methodologies either suffer from inherent accuracy limitations or, in the case of learning-based approaches, perform poorly when applied to ESS despite succeeding on their original datasets. In this study, we present a novel, highly generalizable method that combines Neural Radiance Fields (NeRF) and stereo depth estimation for 3D reconstruction that can derive metric monocular depth. Our approach begins with an initial NeRF reconstruction yielding a coarse 3D scene, the subsequent creation of binocular pairs within coarse 3D scene, and generation of depth maps through stereo vision, These depth maps are used to supervise subsequent NeRF iteration, progressively refining NeRF and binocular depth, the refinement process continues until the depth maps converged. This recursive process generates high-accuracy depth maps from monocular endoscopic video. Evaluation in synthetic endoscopy shows a depth accuracy of 0.125 Â± 0.443 mm, well within the 0.625 mm threshold. Further clinical experiments with real endoscopic data demonstrate a mean distance to CT mesh of 0.269 mm, representing the highest accuracy among monocular 3D reconstruction methods in ESS.
            </p>
        </div>
    </div>
</body>
</html>